{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqt7FqVsAl2w"
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from pymusickit.key_finder import KeyFinder\n",
    "import ipywidgets as widgets\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vocal_remover import direct_call_on_audio_array\n",
    "from decompose import run_decomposer\n",
    "from download_audio import save_youtube_audio, write_audio\n",
    "from notebook_helpers import display_audio\n",
    "from combine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing Tool\n",
    "\n",
    "This notebook demonstrates the main results of the project. It is possible to mix together different songs, extract layers and modify them.\n",
    "\n",
    "To set up the project follow instructions given in the README.md file.\n",
    "\n",
    "How to use this notebook: read the explanations and run cells one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Choose input audio files\n",
    "\n",
    "Provide links to two audio files ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YC7y7v1uouFd"
   },
   "outputs": [],
   "source": [
    "# Add YouTube links for 2 songs you want to mix\n",
    "url1 = '...'\n",
    "url2 = '...'\n",
    "\n",
    "# Saving and loading audio files\n",
    "audiopath1 = save_youtube_audio(url1, 'audio1')\n",
    "audiopath2 = save_youtube_audio(url2, 'audio2')\n",
    "\n",
    "song1 = KeyFinder(audiopath1)\n",
    "song2 = KeyFinder(audiopath2)\n",
    "\n",
    "audio1, sr1 = song1.waveform, song1.sr\n",
    "audio2, sr2 = song2.waveform, song2.sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, specify the timestamps of target audio and source audio ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_len_sec = librosa.get_duration(y=audio1, sr=sr1) # in seconds\n",
    "a2_len_sec = librosa.get_duration(y=audio2, sr=sr2)\n",
    "\n",
    "ts1 = widgets.FloatRangeSlider(\n",
    "    value=[0, a1_len_sec],\n",
    "    min=0, max=a1_len_sec, step=1.0,\n",
    "    description='Audio 1:',\n",
    "    readout=True,\n",
    "    readout_format='.1f',\n",
    ")\n",
    "display(ts1)\n",
    "\n",
    "ts2 = widgets.FloatRangeSlider(\n",
    "    value=[0, a2_len_sec],\n",
    "    min=0, max=a2_len_sec, step=1.0,\n",
    "    description='Audio 2:',\n",
    "    readout=True,\n",
    "    readout_format='.1f',\n",
    ")\n",
    "display(ts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_ts = [ts1.value, ts1.value[1]-ts1.value[0]]\n",
    "a2_ts = [ts2.value, ts2.value[1]-ts2.value[0]]\n",
    "\n",
    "audio1 = audio1[int(a1_ts[0][0]*sr1):int(a1_ts[0][1]*sr1)]\n",
    "audio2 = audio2[int(a2_ts[0][0]*sr2):int(a2_ts[0][1]*sr2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StGoeNir0_by"
   },
   "outputs": [],
   "source": [
    "# Extracting layers\n",
    "fore1, back1 = direct_call_on_audio_array(audio1, sr1)\n",
    "fore2, back2 = direct_call_on_audio_array(audio2, sr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_path1 = os.path.join('audio', 'back1.wav')\n",
    "back_path2 = os.path.join('audio', 'back2.wav')\n",
    "\n",
    "write_audio(back_path1, back1.T, sr1)\n",
    "write_audio(back_path2, back2.T, sr2)\n",
    "_11,_12,perc1 = run_decomposer(back_path1, sr1)\n",
    "_21,_22,perc2 = run_decomposer(back_path2, sr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "uF_2UctH4iY_",
    "outputId": "08800bfd-89ad-4110-dad6-db2961c554a8"
   },
   "outputs": [],
   "source": [
    "shifted_audio = shift_to_match_target_key(song2, song1, fore2, sr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Listen to extracted stems and mix\n",
    "\n",
    "Listen to the extracted background, vocal parts and rhythm..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Backing audio:')\n",
    "display_audio(back1, sr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shifted vocals to match:')\n",
    "display_audio(shifted_audio, sr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percussion track 1:')\n",
    "display_audio(perc1, sr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now choose which stems do you want to mix together and configure the volume of each one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('VOLUME CONFIGURATION')\n",
    "\n",
    "print('Backing:')\n",
    "s1 = widgets.FloatSlider(min=0.0, max=1.0, step=0.1, value=1.0)\n",
    "display(s1)\n",
    "\n",
    "print('Shifted vocals:')\n",
    "s2 = widgets.FloatSlider(min=0.0, max=1.0, step=0.1, value=1.0)\n",
    "display(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed = combine_audio_layers([back1, shifted_audio], [s1.value, s2.value])\n",
    "print('Combined audio:')\n",
    "display_audio(mixed, sr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to adjust the volume further, make sure to run the previous two cells in the same order again until you're satisfied with the mix ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to match the tempo run following cells..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_tempo = match_tempo(shifted_audio, sr2, back1, sr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aenZmiLDdt5N",
    "outputId": "ce5cb6af-b8b4-47b4-81ea-21bf29f50496"
   },
   "outputs": [],
   "source": [
    "final = combine_audio_layers([back1, matched_tempo], [s1.value, s2.value])\n",
    "display_audio(final, sr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
