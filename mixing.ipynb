{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqt7FqVsAl2w"
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from pymusickit.key_finder import KeyFinder\n",
    "import ipywidgets as widgets\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vocal_remover import direct_call_on_audio_array\n",
    "from decompose import run_decomposer\n",
    "from download_audio import save_youtube_audio, write_audio\n",
    "from notebook_helpers import display_audio\n",
    "from combine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing Tool\n",
    "\n",
    "Introductory message here ...\n",
    "\n",
    "Required Python version: 3.10, using conda is recommended...\n",
    "\n",
    "How to use this notebook: read the explanations and run cells one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Choose input audio files\n",
    "\n",
    "Provide links to two audio files ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YC7y7v1uouFd"
   },
   "outputs": [],
   "source": [
    "# Add YouTube links for 2 songs you want to mix\n",
    "url1 = 'https://www.youtube.com/watch?v=ozXZnwYTMbs'\n",
    "url2 = 'https://www.youtube.com/watch?v=84Nby3G1AOE'\n",
    "\n",
    "# Saving and loading audio files\n",
    "audiopath1 = save_youtube_audio(url1, 'audio1')\n",
    "audiopath2 = save_youtube_audio(url2, 'audio2')\n",
    "\n",
    "song1 = KeyFinder(audiopath1)\n",
    "song2 = KeyFinder(audiopath2)\n",
    "\n",
    "audio1, sr1 = song1.waveform, song1.sr\n",
    "audio2, sr2 = song2.waveform, song2.sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StGoeNir0_by"
   },
   "outputs": [],
   "source": [
    "# Extracting layers\n",
    "fore1, back1 = direct_call_on_audio_array(audio1, sr1)\n",
    "fore2, back2 = direct_call_on_audio_array(audio2, sr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_path1 = os.path.join('audio', 'back1.wav')\n",
    "back_path2 = os.path.join('audio', 'back2.wav')\n",
    "\n",
    "write_audio(back_path1, back1.T, sr1)\n",
    "write_audio(back_path2, back2.T, sr2) \n",
    "#_11,_12,perc1 = run_decomposer(back_path1, sr1)\n",
    "#_21,_22,perc2 = run_decomposer(back_path2, sr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "uF_2UctH4iY_",
    "outputId": "08800bfd-89ad-4110-dad6-db2961c554a8"
   },
   "outputs": [],
   "source": [
    "shifted_audio = shift_to_match_target_key(song2, song1, fore2, sr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Listen to extracted stems and mix\n",
    "\n",
    "Listen to the extracted background & vocal parts (also probably rhythm...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Backing audio:')\n",
    "display_audio(back1, sr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shifted vocals to match:')\n",
    "display_audio(shifted_audio, sr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percussion track 1:')\n",
    "#display_audio(perc1, sr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now choose which stems do you want to mix together and configure the volume of each one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('VOLUME CONFIGURATION')\n",
    "\n",
    "print('Backing:')\n",
    "s1 = widgets.FloatSlider(min=0.0, max=1.0, step=0.1, value=1.0)\n",
    "display(s1)\n",
    "\n",
    "print('Shifted vocals:')\n",
    "s2 = widgets.FloatSlider(min=0.0, max=1.0, step=0.1, value=1.0)\n",
    "display(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = combine_audio_layers([back1, shifted_audio], [s1.value, s2.value])\n",
    "print('Combined audio:')\n",
    "display_audio(new, sr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to adjust the volume further, make sure to run the previous two cells in the same order again until you're satisfied with the mix ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_tempo = match_tempo(shifted_audio, sr2, back1, sr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aenZmiLDdt5N",
    "outputId": "ce5cb6af-b8b4-47b4-81ea-21bf29f50496"
   },
   "outputs": [],
   "source": [
    "new = combine_audio_layers([back1, matched_tempo], [s1.value, s2.value])\n",
    "display_audio(new, sr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
