{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pytube\n",
    "# pip install pymusickit\n",
    "# conda install ffmpeg <- must be installed using conda!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqt7FqVsAl2w"
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "from pytube import YouTube\n",
    "import librosa\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "from pymusickit.key_finder import KeyFinder\n",
    "from collections import defaultdict\n",
    "import ipywidgets as widgets\n",
    "import math\n",
    "import soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vocal_remover import direct_call_on_audio_array\n",
    "from decompose import run_decomposer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNvLjxgO_36P"
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "# Convert mp4 to wav\n",
    "def convert_mp4_to_wav(mp4_path):\n",
    "    root, ext = os.path.splitext(mp4_path)\n",
    "    wav_path = root + '.wav'\n",
    "    # Run ffmpeg command\n",
    "    command = ['ffmpeg', '-y','-i', mp4_path, wav_path]\n",
    "    subprocess.run(command, check=True)\n",
    "    return wav_path\n",
    "\n",
    "# Save YouTube video from url\n",
    "def save_youtube_audio(url, filename):\n",
    "    yt = YouTube(url)\n",
    "    video = yt.streams.filter(only_audio = True).first()\n",
    "    filepath = os.path.join('audio', f'{filename}.mp4')\n",
    "    mp4_path = video.download(filename = filepath)\n",
    "    wav_path = convert_mp4_to_wav(mp4_path)\n",
    "    os.remove(mp4_path)\n",
    "    return wav_path\n",
    "\n",
    "# Load audio from file\n",
    "def load_audio_from_file(path, duration = 180):\n",
    "    audio, sr = librosa.load(path, duration = duration)\n",
    "    #audio = np.clip(audio, 0, 1)\n",
    "    return audio, sr\n",
    "\n",
    "# Display audio in notebook\n",
    "def display_audio(audio, sr = None):\n",
    "    return Audio(data = audio, rate = sr)\n",
    "\n",
    "# Save file to disk\n",
    "def write_audio(path, y, sr):\n",
    "    soundfile.write(path, y, sr)\n",
    "\n",
    "# Extract layers (old)\n",
    "def extract_fore_and_background(audio, sample_rate, margin_i = 2, margin_v = 10, power = 2):\n",
    "    audio = np.clip(audio, 0, 1)\n",
    "    S_full, phase = librosa.magphase(librosa.stft(audio))\n",
    "    S_filter = librosa.decompose.nn_filter(S_full,\n",
    "                                        aggregate=np.median,\n",
    "                                        metric='cosine',\n",
    "                                        width=int(librosa.time_to_frames(2, sr=sample_rate)))\n",
    "    S_filter = np.minimum(S_full, S_filter)\n",
    "    mask_i = librosa.util.softmask(S_filter,\n",
    "                               margin_i * (S_full - S_filter),\n",
    "                               power=power)\n",
    "\n",
    "    mask_v = librosa.util.softmask(S_full - S_filter,\n",
    "                                margin_v * S_filter,\n",
    "                                power=power)\n",
    "\n",
    "    S_foreground = mask_v * S_full\n",
    "    S_background = mask_i * S_full\n",
    "\n",
    "    y_foreground = librosa.istft(S_foreground * phase)\n",
    "    y_background = librosa.istft(S_background * phase)\n",
    "\n",
    "    return(y_foreground, y_background)\n",
    "\n",
    "# Define key changes\n",
    "pitches = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "possible_keys = [*[f\"{p} major\" for p in pitches], *[f\"{p} minor\" for p in pitches],]\n",
    "possible_keys.index(\"C minor\")\n",
    "\n",
    "\n",
    "key_to_key_pitch_change = defaultdict(dict)\n",
    "for i in range(len(possible_keys)):\n",
    "    source_key = possible_keys[i]\n",
    "    source_key_type = source_key.split()[1]\n",
    "    for j in range(len(possible_keys)):\n",
    "        target_key = possible_keys[j]\n",
    "        target_key_type = target_key.split()[1]\n",
    "\n",
    "        diff = j-i\n",
    "        if source_key_type == \"minor\" and target_key_type == \"major\":\n",
    "            diff-=3\n",
    "        if source_key_type == \"major\" and target_key_type == \"minor\":\n",
    "            diff+=3\n",
    "\n",
    "        diff = diff % 12\n",
    "        diff = diff if diff<=abs(diff-12) else diff-12\n",
    "        key_to_key_pitch_change[source_key][target_key] = diff\n",
    "\n",
    "# Shift audio to match key       \n",
    "def shift_to_match_target_key(source_song, target_song, source_audio, source_sr):\n",
    "    # Source - will be changed\n",
    "    # Target - base for changing\n",
    "    n_steps = key_to_key_pitch_change[source_song.key_primary][target_song.key_primary]\n",
    "    shifted_audio = librosa.effects.pitch_shift(y = source_audio, sr = source_sr, n_steps = n_steps)\n",
    "    return shifted_audio\n",
    "\n",
    "# Change song tempo\n",
    "def match_tempo(source_audio, source_sr, target_audio, target_sr):\n",
    "    # Source audio = source foreground if you want to modify vocals\n",
    "    source_tempo, _ =  librosa.beat.beat_track(y = source_audio, sr = source_sr)\n",
    "    target_tempo, _ =  librosa.beat.beat_track(y = target_audio, sr = target_sr)\n",
    "    rate = np.round(source_tempo[0] / target_tempo[0], 1)\n",
    "    return librosa.effects.time_stretch(source_audio, rate = rate)\n",
    "\n",
    "\n",
    "def slider_to_db(slider_value, min_db=-40.0, max_db=0.0):\n",
    "    db_value = slider_value * (max_db - min_db) + min_db\n",
    "    return db_value\n",
    "\n",
    "def db_to_amplitude(db_value):\n",
    "    amplitude = 10 ** (db_value / 20.0)\n",
    "    return amplitude\n",
    "\n",
    "def calculate_rms(y,scale=None):\n",
    "    rms = np.sqrt(np.mean(np.square(y)))\n",
    "\n",
    "    if scale:\n",
    "        db_value = slider_to_db(scale)\n",
    "        amp_mult = db_to_amplitude(db_value)\n",
    "        rms = rms * amp_mult\n",
    "    \n",
    "    return rms\n",
    "\n",
    "# Put audio layers together\n",
    "def combine_audio_layers(audio_list, vol_list):\n",
    "    lengths = [len(audio) for audio in audio_list]\n",
    "    length = min(lengths)\n",
    "    \n",
    "    if len(audio_list) == len(vol_list):\n",
    "        combined = audio_list[0][:length] * calculate_rms(audio_list[0], scale=vol_list[0])\n",
    "\n",
    "        # Set volume level of each audio file from given list\n",
    "        for audio,vol in zip(audio_list[1:],vol_list[1:]):\n",
    "            adjusted_audio = audio * calculate_rms(audio, scale=vol)\n",
    "            combined = combined + adjusted_audio[:length]\n",
    "    else:\n",
    "        # Set volume level based on first audio file\n",
    "        combined = audio_list[0][:length]\n",
    "        target_rms = calculate_rms(audio_list[0]) # Choose first layer as target\n",
    "        for audio in audio_list[1:]:\n",
    "            rate = target_rms / calculate_rms(audio) # Set volume\n",
    "            adjusted_audio = audio * rate\n",
    "            combined = combined + adjusted_audio[:length]\n",
    "    return combined / np.max(np.abs(combined))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing Tool\n",
    "\n",
    "Introductory message here ...\n",
    "\n",
    "Required Python version: 3.10, using conda is recommended...\n",
    "\n",
    "How to use this notebook: read the explanations and run cells one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Choose input audio files\n",
    "\n",
    "Provide links to two audio files ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YC7y7v1uouFd"
   },
   "outputs": [],
   "source": [
    "# Add YouTube links for 2 songs you want to mix\n",
    "url1 = 'https://www.youtube.com/watch?v=ozXZnwYTMbs'\n",
    "url2 = 'https://www.youtube.com/watch?v=84Nby3G1AOE'\n",
    "\n",
    "# Saving and loading audio files\n",
    "audiopath1 = save_youtube_audio(url1, 'audio1')\n",
    "audiopath2 = save_youtube_audio(url2, 'audio2')\n",
    "\n",
    "song1 = KeyFinder(audiopath1)\n",
    "song2 = KeyFinder(audiopath2)\n",
    "\n",
    "audio1, sr1 = song1.waveform, song1.sr\n",
    "audio2, sr2 = song2.waveform, song2.sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StGoeNir0_by"
   },
   "outputs": [],
   "source": [
    "# Extracting layers\n",
    "fore1, back1 = direct_call_on_audio_array(audio1, sr1)\n",
    "fore2, back2 = direct_call_on_audio_array(audio2, sr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_audio('back1.wav', back1.T, sr1)\n",
    "write_audio('back2.wav', back2.T, sr2) \n",
    "_11,_12,perc1 = run_decomposer('back1.wav', sr1)\n",
    "_21,_22,perc2 = run_decomposer('back2.wav', sr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "uF_2UctH4iY_",
    "outputId": "08800bfd-89ad-4110-dad6-db2961c554a8"
   },
   "outputs": [],
   "source": [
    "shifted_audio = shift_to_match_target_key(song2, song1, fore2, sr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Listen to extracted stems and mix\n",
    "\n",
    "Listen to the extracted background & vocal parts (also probably rhythm...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Backing audio:')\n",
    "display_audio(back1, sr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shifted vocals to match:')\n",
    "display_audio(shifted_audio, sr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percussion track 1:')\n",
    "display_audio(perc1, sr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now choose which stems do you want to mix together and configure the volume of each one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('VOLUME CONFIGURATION')\n",
    "\n",
    "print('Backing:')\n",
    "s1 = widgets.FloatSlider(min=0.0, max=1.0, step=0.1, value=1.0)\n",
    "display(s1)\n",
    "\n",
    "print('Shifted vocals:')\n",
    "s2 = widgets.FloatSlider(min=0.0, max=1.0, step=0.1, value=1.0)\n",
    "display(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = combine_audio_layers([back1, shifted_audio], [s1.value, s2.value])\n",
    "print('Combined audio:')\n",
    "display_audio(new, sr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to adjust the volume further, make sure to run the previous two cells in the same order again until you're satisfied with the mix ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_tempo = match_tempo(shifted_audio, sr1, back2, sr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aenZmiLDdt5N",
    "outputId": "ce5cb6af-b8b4-47b4-81ea-21bf29f50496"
   },
   "outputs": [],
   "source": [
    "new = combine_audio_layers([back2, matched_tempo])\n",
    "display_audio(new, sr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
